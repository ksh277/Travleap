/**
 * ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
 *
 * ëª©ì :
 * - PlanetScale ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¤‘ìš” ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ë°±ì—…
 * - ì •ê¸°ì ì¸ ë°±ì—… ìë™í™” (cron job ê¶Œì¥)
 *
 * ì‚¬ìš©ë²•:
 * npx tsx scripts/backup-database.ts
 *
 * ë°±ì—… ëŒ€ìƒ í…Œì´ë¸”:
 * - users, listings, bookings, payments, reviews ë“±
 *
 * ë°±ì—… íŒŒì¼ ìœ„ì¹˜:
 * - backups/backup-YYYY-MM-DD-HH-mm.json
 */

import * as dotenv from 'dotenv';
import * as fs from 'fs';
import * as path from 'path';
import { db } from '../utils/database';

dotenv.config();

interface BackupData {
  timestamp: string;
  database: string;
  tables: Record<string, any[]>;
  metadata: {
    totalRows: number;
    backupSize: string;
    tablesBackedUp: string[];
  };
}

// ë°±ì—…í•  í…Œì´ë¸” ëª©ë¡
const TABLES_TO_BACKUP = [
  'users',
  'listings',
  'bookings',
  'payments',
  'reviews',
  'partners',
  'banners',
  'blogs',
  'blog_comments',
  'cart_items',
  'feature_flags',
  'payment_events',
  'booking_logs'
];

/**
 * í…Œì´ë¸” ë°ì´í„° ë°±ì—…
 */
async function backupTable(tableName: string): Promise<any[]> {
  try {
    console.log(\`  ğŸ“¦ Backing up table: \${tableName}...\`);

    const rows = await db.query(\`SELECT * FROM \${tableName}\`);

    console.log(\`  âœ… \${tableName}: \${rows.length} rows backed up\`);
    return rows;
  } catch (error) {
    console.error(\`  âŒ Error backing up \${tableName}:\`, error instanceof Error ? error.message : String(error));
    return [];
  }
}

/**
 * ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
 */
async function backupDatabase(): Promise<BackupData | null> {
  console.log('ğŸ—„ï¸  Starting database backup...\n');

  const backup: BackupData = {
    timestamp: new Date().toISOString(),
    database: 'PlanetScale Database',
    tables: {},
    metadata: {
      totalRows: 0,
      backupSize: '0 KB',
      tablesBackedUp: []
    }
  };

  let totalRows = 0;

  for (const tableName of TABLES_TO_BACKUP) {
    const rows = await backupTable(tableName);

    if (rows.length > 0) {
      backup.tables[tableName] = rows;
      backup.metadata.tablesBackedUp.push(tableName);
      totalRows += rows.length;
    }
  }

  backup.metadata.totalRows = totalRows;

  // ë°±ì—… íŒŒì¼ í¬ê¸° ê³„ì‚°
  const backupString = JSON.stringify(backup, null, 2);
  const backupSizeKB = (backupString.length / 1024).toFixed(2);
  const backupSizeMB = (parseFloat(backupSizeKB) / 1024).toFixed(2);

  backup.metadata.backupSize = parseFloat(backupSizeMB) > 1
    ? \`\${backupSizeMB} MB\`
    : \`\${backupSizeKB} KB\`;

  console.log('\nğŸ“Š Backup Summary:');
  console.log(\`  Total Tables: \${backup.metadata.tablesBackedUp.length}\`);
  console.log(\`  Total Rows: \${backup.metadata.totalRows.toLocaleString()}\`);
  console.log(\`  Backup Size: \${backup.metadata.backupSize}\`);

  return backup;
}

/**
 * ë°±ì—… íŒŒì¼ ì €ì¥
 */
function saveBackup(backup: BackupData): string {
  // backups ë””ë ‰í† ë¦¬ ìƒì„±
  const backupsDir = path.join(process.cwd(), 'backups');

  if (!fs.existsSync(backupsDir)) {
    fs.mkdirSync(backupsDir, { recursive: true});
    console.log(\`\nğŸ“ Created backups directory: \${backupsDir}\`);
  }

  // ë°±ì—… íŒŒì¼ëª… ìƒì„± (backup-2024-01-15-14-30.json)
  const timestamp = new Date()
    .toISOString()
    .replace(/[:.]/g, '-')
    .replace('T', '-')
    .substring(0, 16);

  const backupFileName = \`backup-\${timestamp}.json\`;
  const backupFilePath = path.join(backupsDir, backupFileName);

  // ë°±ì—… íŒŒì¼ ì €ì¥
  fs.writeFileSync(backupFilePath, JSON.stringify(backup, null, 2), 'utf-8');

  console.log(\`\nâœ… Backup saved successfully:\`);
  console.log(\`  File: \${backupFilePath}\`);
  console.log(\`  Size: \${backup.metadata.backupSize}\`);

  return backupFilePath;
}

/**
 * ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬ (7ì¼ ì´ìƒ)
 */
function cleanupOldBackups(retentionDays: number = 7) {
  const backupsDir = path.join(process.cwd(), 'backups');

  if (!fs.existsSync(backupsDir)) {
    return;
  }

  console.log(\`\nğŸ§¹ Cleaning up backups older than \${retentionDays} days...\`);

  const files = fs.readdirSync(backupsDir);
  const now = Date.now();
  let deletedCount = 0;

  files.forEach(file => {
    if (!file.startsWith('backup-') || !file.endsWith('.json')) {
      return;
    }

    const filePath = path.join(backupsDir, file);
    const stats = fs.statSync(filePath);
    const fileAgeMs = now - stats.mtimeMs;
    const fileAgeDays = fileAgeMs / (1000 * 60 * 60 * 24);

    if (fileAgeDays > retentionDays) {
      fs.unlinkSync(filePath);
      console.log(\`  ğŸ—‘ï¸  Deleted: \${file} (\${fileAgeDays.toFixed(1)} days old)\`);
      deletedCount++;
    }
  });

  if (deletedCount === 0) {
    console.log(\`  âœ… No old backups to delete\`);
  } else {
    console.log(\`  âœ… Deleted \${deletedCount} old backup(s)\`);
  }
}

/**
 * ë©”ì¸ ì‹¤í–‰
 */
async function main() {
  try {
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('   DATABASE BACKUP SCRIPT');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

    // 1. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
    const backup = await backupDatabase();

    if (!backup) {
      throw new Error('Backup failed');
    }

    // 2. ë°±ì—… íŒŒì¼ ì €ì¥
    saveBackup(backup);

    // 3. ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
    cleanupOldBackups(7);

    console.log('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('âœ… Backup completed successfully!');
    console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

    process.exit(0);

  } catch (error) {
    console.error('\nâŒ Backup failed:', error instanceof Error ? error.message : String(error));
    console.error(error);
    process.exit(1);
  }
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main();
